from pybo import BoTokenizer

tok = BoTokenizer('GMD')


def get_last_letter_idx(token):
    if token.syls:
        return token.syls[-1][-1]
    return 0


def segment(tok, string, tagset):
    tokens = tok.tokenize(string, split_affixes=False, lemmatize=False)
    print('ok')
    output = []
    idx = 0
    for t in tokens:
        start = idx

        if t.type == 'syl':
            end = start + len(t.content)
            if t.affixed:
                type = tagset['Aword']  # hard-coded value for segmentation schema
            else:
                type = tagset['Word']  # idem
            output.append((type, start, end))

        idx = start + len(t.content)
    return output


if __name__ == '__main__':
    test = '''འདུ་བ་ཡོད་ན་བྲལ་བར་འོང་། །སྐྱེ་བ་ཡོད་ན་འཆི་བར་འགྱུར། །ཞེས་ཚིགས་སུ་བཅད་པ་འདི་སྨྲས་མ་ཐག་ཏུ། རྒྱལ་པོ་དེ་དགའ་མགུ་རངས་ཏེ། འགྱོད་པའི་སེམས་མེད་བཞིན་དུ་འདི་སྐད་ཅེས་དམ་བཅས་སོ། །བདག་ཆོས་ཚོལ་བ་འདི་ཡང་སངས་རྒྱས་སུ་བསྒྲུབ་པའི་ཕྱིར་ཏེ། ཕྱིས་མངོན་པར་རྫོགས་པས་སངས་རྒྱས་པ་ན། ཡེ་ཤེས་ཀྱི་འོད་ཀྱིས་སེམས་ཅན་གཏི་མུག་གིས་མདོངས་པ་རྣམས་ཤིན་ཏུ་སྣང་བར་གྱུར་ཅིག་ཅེས་ཡི་དམ་བཅས་མ་ཐག་ཏུ་གནམ་ས་ཡང་རབ་ཏུ་གཡོས་སོ། །གནས་གཙང་མའི་རིས་ཀྱི་ལྷའི་ཕོ་བྲང་གི་བར་དུ་གཡོས་པས། ལྷ་དེ་དག་ནམ་མཁའ་ལས་བབས་ཏེ། ལུས་ཀྱིས་མཆོད་པའི་གནས་སུ་ལྷགས་སོ། །བྱང་ཆུབ་སེམས་དཔའ་དེའི་ལུས་དེ་ལྟར་ཞིག་པ་ལྷ་དེ་དག་གིས་མཐོང་ནས། སྟེང་གི་ནམ་མཁའ་ཡོངས་སུ་གང་བ་དེ་དག་ངུས་ཏེ། ངུས་པའི་མཆི་མ་ཆར་བཞིན་དུ་བབ་ནས། ལྷ་རྫས་ཀྱི་མེ་ཏོག་ཀྱང་ཆར་བཞིན་དུ་ཕབ་སྟེ། མཆོད་པ་བྱས་སོ། །དེའི་ཚེ་བརྒྱ་བྱིན་ལྷའི་དབང་པོ་ཡང་རྒྱལ་པོ་གང་ན་དེར་འོངས་ནས། རྣམ་པ་སྣ་ཚོགས་ཀྱིས་བསྟོད་ཅིང་བསྔགས་ཏེ། འདི་སྐད་ཅེས་སྨྲས་སོ། །རྒྱལ་པོ་ཆེན་པོ་འདི་ལྟར་ཤིན་ཏུ་སྡུག་བསྔལ་ཀྱིས་གདུངས་པ་འདི་ལ་སེམས་འགྱོད་པར་འམ་གྱུར་ཏམ། རྒྱལ་པོས་སྨྲས་པ། འགྱོད་པ་མེད་དོ། །བརྒྱ་བྱིན་གྱིས་སྨྲས་པ། རྒྱལ་པོ་ཆེན་པོ་འདི་ལྟར་ལུས་འདར་ཞིང་ཉམས་མི་བདེ་བཞིན་དུ་འགྱོད་པ་མེད་ཅེས་སྨྲས་པ་འདི་ཅིས་ཡིད་ཆེས་པར་འགྱུར། རྒྱལ་པོས་སྨྲས་པ༑ གལ་ཏེ་བདག་ཐོག་མ་ནས་ཐ་མའི་བར་དུ་འགྱོད་པའི་སེམས་མེད་པ་ཡིན་ན། ལུས་ཀྱི་རྨ་འདི་སྔ་མ་བཞིན་དུ་སོས་པར་གྱུར་ཅིག་ཅེས་སྨྲས་མ་ཐག་ཏུ་ལུས་སྔ་མ་ཁོ་ན་བཞིན་དུ་རྨ་མེད་པར་གྱུར་ཏོ། །'''
    segment(tok, test, {'Aword': 'a', 'Word': 'b'})
